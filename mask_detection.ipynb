{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "VJ-Wi6y-hqWP"
   },
   "outputs": [],
   "source": [
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torch\n",
    "import torch.utils\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader\n",
    ")\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import detection.utils  # Get this folder into the project directory https://github.com/pytorch/vision/tree/main/references/detection\n",
    "import detection.engine  # In order to work in Colab, you need to change rows 7-9 of engine.py to:\n",
    "                                                                  #7 import detection.utils\n",
    "                                                                  #8 from detection.coco_eval import CocoEvaluator\n",
    "                                                                  #9 from detection.coco_utils import get_coco_api_from_dataset\n",
    "                                                                  # Also in coco_utils.py you need to change 7th row to: 'import torchvision.transforms as T'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining function, which will return pretrained model with a replaced head"
   ],
   "metadata": {
    "id": "QJGAumC2EkM4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_model_detection(num_classes):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "id": "HY0DBvid1Ai3"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining transforms for train and test sets"
   ],
   "metadata": {
    "id": "aB6RBAIdEw-s"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_transform = FasterRCNN_ResNet50_FPN_Weights.COCO_V1.transforms\n",
    "test_transform = FasterRCNN_ResNet50_FPN_Weights.COCO_V1.transforms"
   ],
   "metadata": {
    "id": "tjwDl3PKgyYU"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_transform(train):\n",
    "    transform = []\n",
    "    transform.append(transforms.PILToTensor())\n",
    "    transform.append(transforms.ConvertImageDtype(torch.float))\n",
    "    if train:\n",
    "        transform.append(transforms.RandomHorizontalFlip(0.5))\n",
    "    return transforms.Compose(transform)"
   ],
   "metadata": {
    "id": "ntCfQO1_4BC7"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating a Dataset class "
   ],
   "metadata": {
    "id": "7lWZ18fOFgT7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class MasksDataset(Dataset):\n",
    "  def __init__(self, root_dir, transform = None):\n",
    "    self.root_dir = root_dir\n",
    "    self.transform = transform\n",
    "    self.images = list(sorted(os.listdir(os.path.join(self.root_dir, \"images\"))))\n",
    "    self.annotations = list(sorted(os.listdir(os.path.join(self.root_dir, \"annotations\"))))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    img_path = os.path.join(self.root_dir, \"images\", self.images[index])\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    annotation_path = os.path.join(self.root_dir, \"annotations\", self.annotations[index])\n",
    "    tree = ET.parse(annotation_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    objects = len(root.findall(\"./object/name\"))\n",
    "\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    for i in range(objects):\n",
    "        coords = []\n",
    "        for j in range(4):\n",
    "            coords.append(int(root[4 + i][5][j].text))\n",
    "        boxes.append(coords)\n",
    "        if root[4 + i][0].text == \"with_mask\":\n",
    "          labels.append(1)\n",
    "        elif root[4 + i][0].text == \"without_mask\":\n",
    "          labels.append(2)\n",
    "        else:\n",
    "          labels.append(3)\n",
    "\n",
    "    boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "    labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "    image_id = torch.tensor([index])\n",
    "    area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "    iscrowd = torch.zeros((objects,), dtype=torch.int64)\n",
    "    target = {}\n",
    "    target[\"boxes\"] = boxes\n",
    "    target[\"labels\"] = labels\n",
    "    target[\"image_id\"] = image_id\n",
    "    target[\"area\"] = area\n",
    "    target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "    if self.transform is not None:\n",
    "      img = self.transform(img)  \n",
    "\n",
    "    return img, target\n",
    "\n"
   ],
   "metadata": {
    "id": "HEsCdVotIIij"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_path = r\"/content/drive/MyDrive/FaceMaskDetection\"\n",
    "\n",
    "train_set = MasksDataset(root_dir= dataset_path, transform=get_transform(train=True))\n",
    "test_set = MasksDataset(root_dir= dataset_path, transform=get_transform(train=False))"
   ],
   "metadata": {
    "id": "Wak4QdbOFfl-"
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = get_model_detection(4)"
   ],
   "metadata": {
    "id": "QRDOJmK6v6JN"
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataloader = DataLoader(\n",
    " train_set, batch_size=2, shuffle=True, num_workers=2,\n",
    " collate_fn=detection.utils.collate_fn)"
   ],
   "metadata": {
    "id": "xcJA6uSFpOcG"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell for testing outputs\n",
    "images,targets = next(iter(dataloader))\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "output = model(images,targets)\n",
    "model.eval()\n",
    "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "predictions = model(x)\n",
    "predictions"
   ],
   "metadata": {
    "id": "QAnyTfkdwyY3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training"
   ],
   "metadata": {
    "id": "vcIvcE3I2xeX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# split the dataset in train and test set\n",
    "indices = torch.randperm(len(train_set)).tolist()\n",
    "dataset = torch.utils.data.Subset(train_set, indices[:-50])\n",
    "dataset_test = torch.utils.data.Subset(test_set, indices[-50:])\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=2, shuffle=True, num_workers=2,\n",
    "    collate_fn=detection.utils.collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=2,\n",
    "    collate_fn=detection.utils.collate_fn)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                                momentum=0.9, weight_decay=0.0005)\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                step_size=3,\n",
    "                                                gamma=0.1)\n",
    "\n",
    "# let's train it for 10 epochs\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    detection.engine.train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    torch.save(model.state_dict(), '/content/drive/MyDrive/FaceMaskDetection/model_weights-' + str(epoch) + '.pth')\n",
    "    # evaluate on the test dataset\n",
    "    detection.engine.evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "print(\"Training is over\")"
   ],
   "metadata": {
    "id": "mmS-T-Qt20TY"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
